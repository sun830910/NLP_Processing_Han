{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯\n",
    "朴素贝叶斯的朴素意指假设用以分类的属性彼此互相独立。  \n",
    "  \n",
    "可以使用词袋向量计算TF-IDF表示后再使用朴素贝叶斯进行分类。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信息熵\n",
    "若说概率是对事件确定性的度量，那么信息（包括信息量和信息熵）就是对事物不确定性的度量。  \n",
    "  \n",
    "1. 信息熵的本质是信息量的度量。\n",
    "2. 信息熵是对随机变量不确定性的度量。随机变量X的熵越大，说明它的不确定性也越大，若随机变量退化为定量，则熵为0。  \n",
    "3. 平均分布是最不确定的分布。  \n",
    "\n",
    "# 互信息\n",
    "信源发出x的概率p(x)称为先验概率，通过信道后信宿可能收到受干扰作用引起的某种变形y，信宿收到y后推测信源发出x的概率称为后验概率。  \n",
    "x的后验概率与先验概率比值的对数为y对x的互信息量=log(P(y|x) / P(y))。  \n",
    "  \n",
    "互信息性质：  \n",
    "1. 互信息可以理解为收信者收到信号X后，对信源Y的不确定性的消除。\n",
    "2. 互信息=I(先验事件)-I(后验事件)=log(后验概率/先验概率)。  \n",
    "3. 互信息是对称的。   \n",
    "  \n",
    "平均互信息又称为信息增益。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
